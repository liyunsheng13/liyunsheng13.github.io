---
permalink: /
title: "Yunsheng Li"
excerpt: "Yunsheng Li"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Yunsheng Li is a Senior Researcher Microsoft Azure GenAI Group. He is working on the development for the multi-modality large language model at Microsoft. His research interests include computer vision (segmentation, domain adaptation), deep learning (network architecture design) and multi-modality large language models. His representative works include [phi-3-vision](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct), [MicroNet](http://www.svcl.ucsd.edu/projects/micronet/), and [BDL](https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Bidirectional_Learning_for_Domain_Adaptation_of_Semantic_Segmentation_CVPR_2019_paper.pdf). 

Research Experiences
======
- **2024-present:** Working on the supervised fine-tuning for [Phi-3-vision](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct) and [Phi-3.5-vision](https://huggingface.co/microsoft/Phi-3.5-vision-instruct) project, developing one of the best "small" multi-modal LLMs.
- **2022-2023:** Design the background removal models that are used in [Windows Paint and Photo](https://blogs.windows.com/windows-insider/2023/09/07/background-removal-in-paint-begins-rolling-out-to-windows-insiders) and [Microsoft Desiger](https://create.microsoft.com/en-us/features/image-background-remover)
- **2015-2021:** A Ph.D. student in University of California, San Diego, working on overcoming the resource constrained computer vision related topics, e.g., [efficient neural network architecture design and domain adaptation](http://www.svcl.ucsd.edu/people/yunsheng/thesis.pdf). 


Publications
======
9. **Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone** <br>
   Microsoft GenAI team <br>
   [[arXiv]](https://arxiv.org/abs/2404.14219) [[HuggingFace]](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct)
8. **Rethinking Visual Prompting for Multimodal Large Language Models with External Knowledge** <br>
   Yuanze Lin, Yunsheng Li, Dongdong Chen, Weijian Xu, Ronald Clark, Philip Torr, Lu Yuan <br>
   [[arXiv]](https://arxiv.org/pdf/2407.04681)  </span> 
2. **Deep High-Resolution Representation Learning for Human Pose Estimation** <br>
   Ke Sun, Bin Xiao, Dong Liu, Jingdong Wang <br>
   Conference on Computer Vision and Pattern Recognition (**CVPR**), 2019 <br>
   [[Paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_Deep_High-Resolution_Representation_Learning_for_Human_Pose_Estimation_CVPR_2019_paper.pdf) [[Code]](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch) [<span style="color:red"> **Paper Digest Most Influential CVPR Papers** </span>](https://www.paperdigest.org/2022/05/most-influential-cvpr-papers-2022-05/)
   <div><iframe src="https://ghbtns.com/github-btn.html?user=leoxiaobin&repo=deep-high-resolution-net.pytorch&type=star&count=true" frameborder="0" scrolling="0" width="94px" height="20px"></iframe></div>
5. **CvT: Introducing Convolutions to Vision Transformers** <br>
   Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang <br>
   International Conference on Computer Vision (**ICCV**), 2021<br>
   [[Paper]](https://openaccess.thecvf.com/content/ICCV2021/papers/Wu_CvT_Introducing_Convolutions_to_Vision_Transformers_ICCV_2021_paper.pdf) [[Code]](https://github.com/microsoft/CvT) [<span style="color:red"> **Paper Digest Most Influential ICCV Papers** </span>](https://www.paperdigest.org/2022/05/most-influential-iccv-papers-2022-05/)
   <div><iframe src="https://ghbtns.com/github-btn.html?user=microsoft&repo=CvT&type=star&count=true" frameborder="0" scrolling="0" width="94px" height="20px"></iframe></div>
1. **Simple baselines for human pose estimation and tracking** <br>
   Bin Xiao, Haiping Wu, Yichen Wei <br>
   European Conference on Computer Vision (**ECCV**), 2018 <br>
   [[Paper]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Bin_Xiao_Simple_Baselines_for_ECCV_2018_paper.pdf) [[Code]](https://github.com/microsoft/human-pose-estimation.pytorch) [<span style="color:red"> **Paper Digest Most Influential ECCV Papers** </span>](https://www.paperdigest.org/2022/05/most-influential-eccv-papers-2022-05/)
   <div><iframe src="https://ghbtns.com/github-btn.html?user=microsoft&repo=human-pose-estimation.pytorch&type=star&count=true" frameborder="0" scrolling="0" width="94px" height="20px"></iframe></div>
7. **DaViT: Dual Attention Vision Transformers** <br>
   Mingyu Ding, Bin Xiao, Noel Codella, Ping Luo, Jingdong Wang, Lu Yuan <br>
   European Conference on Computer Vision (**ECCV**), 2022 <br>
6. **Unified contrastive learning in image-text-label space** <br>
   Jianwei Yang, Chunyuan Li, Pengchuan Zhang, Bin Xiao, Ce Liu, Lu Yuan, Jianfeng Gao <br> 
    Conference on Computer Vision and Pattern Recognition (**CVPR**), 2022 <br>
    [[Paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Unified_Contrastive_Learning_in_Image-Text-Label_Space_CVPR_2022_paper.pdf)
6. **Florence: A New Foundation Model for Computer Vision** <br>
   Lu Yuan, Dongdong Chen, Yi-Ling Chen, Noel Codella, Xiyang Dai, Jianfeng Gao, Houdong Hu, Xuedong Huang, Boxin Li, Chunyuan Li, Ce Liu, Mengchen Liu, Zicheng Liu, Yumao Lu, Yu Shi, Lijuan Wang, Jianfeng Wang, Bin Xiao, Zhen Xiao, Jianwei Yang, Michael Zeng, Luowei Zhou, Pengchuan Zhang <br>
   [[arXiv]](https://arxiv.org/pdf/2111.11432)
4. **Lite-hrnet: A lightweight high-resolution network** <br>
   Changqian Yu, Bin Xiao, Changxin Gao, Lu Yuan, Lei Zhang, Nong Sang, Jingdong Wang <br>
   Conference on Computer Vision and Pattern Recognition (**CVPR**), 2021 <br>
   [[Paper]](http://openaccess.thecvf.com/content/CVPR2021/papers/Yu_Lite-HRNet_A_Lightweight_High-Resolution_Network_CVPR_2021_paper.pdf) [[Code]](https://github. com/HRNet/Lite-HRNet)
   <div><iframe src="https://ghbtns.com/github-btn.html?user=HRNet&repo=Lite-HRNet&type=star&count=true" frameborder="0" scrolling="0" width="94px" height="20px"></iframe></div>
3. **HigherHRNet: Scale-Aware Representation Learning for Bottom-Up Human Pose Estimation** <br>
   Bowen Cheng, Bin Xiao, Jingdong Wang, Honghui Shi, Thomas S Huang, Lei Zhang <br>
   Conference on Computer Vision and Pattern Recognition (**CVPR**), 2020 <br>
   [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Cheng_HigherHRNet_Scale-Aware_Representation_Learning_for_Bottom-Up_Human_Pose_Estimation_CVPR_2020_paper.pdf) [[Code]](https://github.com/HRNet/HigherHRNet-Human-Pose-Estimation)
   <div><iframe src="https://ghbtns.com/github-btn.html?user=HRNet&repo=HigherHRNet-Human-Pose-Estimation&type=star&count=true" frameborder="0" scrolling="0" width="94px" height="20px"></iframe></div>
3. **Deep High-Resolution Representation Learning for Visual Recognition** <br>
   Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang, Chaorui Deng, Yang Zhao, Dong Liu, Yadong Mu, Mingkui Tan, Xinggang Wang, Wenyu Liu, Bin Xiao <br>
   IEEE Transactions on Pattern Analysis and Machine Intelligence (**PAMI**), 2020 <br>
   [[Paper]](https://arxiv.org/pdf/1908.07919)
2. **Integral human pose regression** <br>
   Xiao Sun, Bin Xiao, Fangyin Wei, Shuang Liang, Yichen Wei <br>
    European Conference on Computer Vision (**ECCV**), 2018 <br>
    [[Paper]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Xiao_Sun_Integral_Human_Pose_ECCV_2018_paper.pdf)




Professinonal Activities
======
- Conference reviewer: CVPR, ICCV, ECCV, ICLR, and et.al. 
- Journal reviewer: T-PAMI, T-MM, IJCV, and et.al.
